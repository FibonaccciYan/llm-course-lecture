{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b74163b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello from torch-test!\n",
      "Excellent! MPS backend is available.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "def main():\n",
    "    print(\"Hello from torch-test!\")\n",
    "    if torch.backends.mps.is_available():\n",
    "        print(\"Excellent! MPS backend is available.\")\n",
    "    else:\n",
    "        print(\"MPS backend is not available: Something went wrong! Are you running this on a Mac with Apple Silicon chip?\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40368757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.1574, -0.5219, -0.5566,  0.3880],\n",
      "         [-0.1867,  0.5207, -0.8282, -1.5612],\n",
      "         [ 0.3143,  0.1646,  0.9471,  0.1488]],\n",
      "\n",
      "        [[-0.1375,  0.6165,  0.2010, -0.7181],\n",
      "         [ 1.0336, -0.3422,  1.0562,  1.1867],\n",
      "         [-0.1696, -0.4101,  1.1450, -0.9568]]], requires_grad=True)\n",
      "tensor([[[ 0.1167],\n",
      "         [-0.5138],\n",
      "         [ 0.3937]],\n",
      "\n",
      "        [[-0.0095],\n",
      "         [ 0.7336],\n",
      "         [-0.0979]]], grad_fn=<MeanBackward1>)\n",
      "tensor([[ 0.4284,  0.0545, -0.1459, -0.3415],\n",
      "        [ 0.2422, -0.0453,  0.8007, -0.1627]], grad_fn=<MeanBackward1>)\n"
     ]
    }
   ],
   "source": [
    "input = torch.randn(2,3,4, requires_grad=True)\n",
    "\n",
    "print(input)\n",
    "print(input.mean(-1, keepdim=True))\n",
    "print(input.mean(1))\n",
    "\n",
    "variance_epsilon = 1e-6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e66e00b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.6080, -0.7250, -0.7733,  0.5391],\n",
      "         [-0.2016,  0.5624, -0.8945, -1.6861],\n",
      "         [ 0.6149,  0.3221,  1.8529,  0.2911]],\n",
      "\n",
      "        [[-0.2814,  1.2617,  0.4114, -1.4696],\n",
      "         [ 1.0733, -0.3553,  1.0968,  1.2324],\n",
      "         [-0.2179, -0.5269,  1.4710, -1.2292]]], grad_fn=<MulBackward0>)\n",
      "tensor([[[ 1.6080, -0.7250, -0.7733,  0.5391],\n",
      "         [-0.2016,  0.5624, -0.8945, -1.6861],\n",
      "         [ 0.6149,  0.3221,  1.8529,  0.2911]],\n",
      "\n",
      "        [[-0.2814,  1.2617,  0.4114, -1.4696],\n",
      "         [ 1.0733, -0.3553,  1.0968,  1.2324],\n",
      "         [-0.2179, -0.5269,  1.4710, -1.2292]]], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "input = input.to(torch.float32)\n",
    "variance = input.pow(2).mean(-1, keepdim=True)\n",
    "hidden_states = input * torch.rsqrt(variance + variance_epsilon)\n",
    "# print(0.1089**2, input.pow(2))\n",
    "\n",
    "layerNorm = nn.RMSNorm([4])\n",
    "hidden_states1 = layerNorm(input)\n",
    "print(hidden_states)\n",
    "print(hidden_states1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fdcf1710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original token 0: tensor([[[ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.],\n",
      "         [ 8.,  9., 10., 11., 12., 13., 14., 15.],\n",
      "         [16., 17., 18., 19., 20., 21., 22., 23.],\n",
      "         [24., 25., 26., 27., 28., 29., 30., 31.]]])\n",
      "after RoPE    : tensor([[[  0.0000,   1.0000,   2.0000,   3.0000,   4.0000,   5.0000,   6.0000,\n",
      "            7.0000],\n",
      "         [ -3.2508,  11.5945,   8.8519,  11.9434,  11.8694,  13.1193,  13.9850,\n",
      "           15.0140],\n",
      "         [-22.1164,   7.4743,  13.8665,  22.1973,  19.5760,  21.3958,  21.9540,\n",
      "           23.0440],\n",
      "         [-27.2878, -21.3629,  16.8597,  33.4776,  27.1175,  29.8268,  29.9069,\n",
      "           31.0899]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def build_rope_cache(seq_len, dim, base=10000, device=None):\n",
    "    device = device or torch.device('cpu')\n",
    "    position = torch.arange(seq_len, dtype=torch.float32, device=device)\n",
    "    dim_idx = torch.arange(dim // 2, dtype=torch.float32, device=device)\n",
    "    inv_freq = base ** (-dim_idx / (dim // 2))\n",
    "    freqs = torch.outer(position, inv_freq)\n",
    "    cos = torch.cos(freqs)\n",
    "    sin = torch.sin(freqs)\n",
    "    return cos, sin\n",
    "\n",
    "def apply_rope(x, cos, sin):\n",
    "    cos = cos.unsqueeze(0)\n",
    "    sin = sin.unsqueeze(0)\n",
    "    x_even = x[..., ::2]\n",
    "    x_odd = x[..., 1::2]\n",
    "    rotated_even = x_even * cos - x_odd * sin\n",
    "    rotated_odd = x_odd * cos + x_even * sin\n",
    "    rotated = torch.stack([rotated_even, rotated_odd], dim=-1).flatten(-2)\n",
    "    return rotated\n",
    "\n",
    "seq_len, dim = 4, 8\n",
    "hidden_states = torch.arange(seq_len * dim, dtype=torch.float32).view(1, seq_len, dim)\n",
    "cos, sin = build_rope_cache(seq_len, dim, device=hidden_states.device)\n",
    "rope_hidden = apply_rope(hidden_states, cos, sin)\n",
    "print('original token 0:', hidden_states)\n",
    "print('after RoPE    :', rope_hidden)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
