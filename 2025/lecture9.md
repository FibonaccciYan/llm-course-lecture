---
theme: gaia
_class: lead
paginate: true
backgroundColor: #fff
# backgroundImage: url('https://marp.app/assets/hero-background.svg')
marp: true
---
<style>
img[alt~="center"] {
  display: block;
  margin: 0 auto;
}
a[href='red'] {
    color: red;
    pointer-events: none;
    cursor: default;
    text-decoration: none;
}
</style>

<style>
img[alt~="right"] {
  display: block;
  margin:auto;
}
a[href='red'] {
    color: red;
    pointer-events: none;
    cursor: default;
    text-decoration: none;
}
</style>


![bg left:45% 80%](../images/course.webp)

# **LLMæ™ºèƒ½åº”ç”¨å¼€å‘**

ç¬¬9è®²: Sparse Attention

---

## èƒŒæ™¯ä¸åŠ¨æœº

### å›é¡¾ Self-Attention æœºåˆ¶

$$
A = Softmax(\frac{QK^T}{\sqrt{d}})V
$$

å…¶ä¸­ $Q$ shape: [bs, nh, q_len, hd], $KV$ shape: [bs, nh, kv_len, hd]ï¼Œ

è‹¥è®° $N$ ä¸ºåºåˆ—é•¿åº¦ï¼Œåˆ™ $q\_len \in O(N), kv\_len \in O(N)$ï¼Œ

å› æ­¤ Attention çš„è®¡ç®—å¤æ‚åº¦æ˜¯ $O(N^2)$ã€‚

---

### é•¿æ–‡æœ¬åœºæ™¯

åœ¨è¾“å…¥åºåˆ—è¾ƒé•¿çš„åº”ç”¨åœºæ™¯ä¸­ï¼Œä¾‹å¦‚ï¼š
* ç”Ÿæˆé•¿æ–‡æ¡£æ€»ç»“
* å¤§è§„æ¨¡ä»£ç åˆ†æ
* å¤šæ–‡æ¡£é—®ç­”
* å¤šè½®å¯¹è¯
  
å¹³æ–¹çº§çš„å¤æ‚åº¦å¯¼è‡´ Self-Attention è®¡ç®—é€Ÿåº¦æ˜¾è‘—å˜æ…¢ï¼Œé™åˆ¶äº†å¤§æ¨¡å‹åœ¨è¿™äº›åœºæ™¯ä¸­çš„å¹¿æ³›åº”ç”¨ã€‚

---

### æ€è€ƒ

æœ¬è´¨ä¸Šï¼Œè®¡ç®— Self-Attention çš„è¿‡ç¨‹å°±æ˜¯è®©æ‰€æœ‰ token â€œæ³¨æ„â€ å…¶ä»–æ‰€æœ‰ token çš„è¿‡ç¨‹ã€‚

è”æƒ³ï¼šå¹³æ—¶æˆ‘ä»¬åœ¨é˜…è¯»æ–‡ç« æ—¶ï¼Œå¹¶ä¸ä¼šä¸€ä¸ªå­—ä¸€ä¸ªå­—åœ°ç†è§£ï¼Œå¾€å¾€æ˜¯é€šè¯»ä¸€éæŠ“ä½å…³é”®è¯ï¼Œå°±èƒ½æŒæ¡å¤§è‡´æ„æ€ã€‚

ğŸ” **é—®é¢˜ï¼šçœŸçš„éœ€è¦æ¯ä¸ª token éƒ½â€œæ³¨æ„â€æ‰€æœ‰å…¶ä»– token å—ï¼Ÿ**

---

### è§‚å¯Ÿ

åœ¨ llama3 æ¨¡å‹ä¸Šè¾“å…¥ "A is B. C is D. A is" å¹¶è®¾ç½® max_new_tokens=1 (prefill) å¾—åˆ°ä»¥ä¸‹ Attention Heatmapï¼ˆéƒ¨åˆ†ï¼‰ï¼Œå…¶ä¸­é¢œè‰²ç”±æš—åˆ°äº®ï¼ˆç”±ç´«åˆ°é»„ï¼‰è¡¨ç¤ºæ¿€æ´»å€¼ä»å°åˆ°å¤§ï¼ˆ0-1ï¼‰ã€‚

<img src="../images/l9/sparsity.png" width="100%" />

---

### ç¨€ç–æ€§ï¼ˆSparsityï¼‰

åœ¨ Self-Attention è®¡ç®—è¿‡ç¨‹ä¸­:
* **ç°è±¡**ï¼šæ³¨æ„åŠ›çŸ©é˜µä¸­ï¼Œå¤§éƒ¨åˆ†æƒé‡æ¥è¿‘ 0;
* **å¯å‘**ï¼šå¯ä»¥åªä¿ç•™æœ€å…³é”®çš„è¿æ¥å‚ä¸è®¡ç®—ï¼›
* **ç›®æ ‡**ï¼šå‡å°‘æ— ç”¨è®¡ç®—ï¼Œæé«˜æ•ˆç‡ã€‚

---

## Sparse Attention

Sparse Attention å¯ä»¥å¦‚ä¸‹è¡¨è¿°ï¼š

$$
\hat{A} = Softmax(\frac{QK_s^T}{\sqrt{d}})V_s
$$

å…¶ä¸­ $K_s, V_s$ å‡ä¸ºä»å®Œæ•´ $KV$ ä¸­ç­›é€‰å‡ºæ¥çš„éƒ¨åˆ† $KV$ï¼Œä¸” $s \ll N$ã€‚

ä¾‹å¦‚ï¼Œå¯¹äº $N=8k$ çš„è¾“å…¥ï¼Œå¯ä»¥å– $s=2k$ï¼Œç¨€ç–æ¯”ä¾‹è¾¾åˆ° $\frac{1}{4}$ï¼Œç”±æ­¤å°†è®¡ç®—é‡é™ä½åˆ° $\frac{1}{16}$ã€‚

---

### Sparse Attention åˆ†ç±»

1. æ ¹æ®å¦‚ä½•ç­›é€‰å…³é”® tokenï¼š
   * Static pattern
   * Dynamic pattern
2. æ ¹æ®æ˜¯å¦éœ€è¦è®­ç»ƒï¼š
   * Training-free
   * Training-based

ç”±äºè®­ç»ƒéœ€è¦æ¶ˆè€—å¤§é‡èµ„æºï¼Œå­¦æœ¯ç•Œä¸»è¦èšç„¦åœ¨ Training-free æˆ–åªè¦ç®€å•è®­ç»ƒçš„æ–¹æ³•ä¸Šï¼›è€Œéƒ¨åˆ†å¤§æ¨¡å‹å‚å•†ï¼ˆå¦‚ DeepSeekï¼‰æ­£åœ¨å°è¯• Training-based Sparse Attentionã€‚

---

### Static pattern æ–¹æ³•ç®€ä»‹

1. Sliding windows: ç»´æŠ¤ä¸€ä¸ªå›ºå®šå¤§å°çš„çª—å£ï¼Œä¿ç•™æœ€è¿‘çš„ tokens å‚ä¸è®¡ç®—ï¼Œå…¶ä½™å…¨éƒ¨ä¸¢å¼ƒã€‚

   * ä¼˜ç‚¹ï¼šå®ç°ç®€å•ï¼Œè®¡ç®—å¤æ‚åº¦é™ä½åˆ° $O(N)$ï¼›
   * ç¼ºç‚¹ï¼šç²¾åº¦æŸå¤±è¾ƒå¤§ï¼Œå°¤å…¶æ˜¯åœ¨é•¿åº¦è¶…è¿‡é¢„è®­ç»ƒé•¿åº¦åå¤§å¹…ä¸‹é™ã€‚

![sliding_window center](../images/l9/sliding_window.png)

---

### Static pattern æ–¹æ³•ç®€ä»‹

2. Attention sinks: [StreamingLLM](https://arxiv.org/abs/2309.17453) å‘ç°æ³¨æ„åŠ›æƒé‡å¾€å¾€ä¼šé›†ä¸­åœ¨é¦– token ä¸Šï¼Œå°†è¿™ä¸€ç°è±¡ç§°ä¸º attention sinksã€‚åŸºäºè¯¥å‘ç°ï¼ŒStreamingLLM åœ¨ sliding window çš„åŸºç¡€ä¸Šè¿›ä¸€æ­¥ä¿ç•™ attention sinksï¼Œé™ä½äº†é•¿æ–‡æœ¬åœºæ™¯ä¸‹ç¨€ç–å¯¼è‡´çš„ç²¾åº¦æŸå¤±ã€‚

![streamingllm center](../images/l9/streamingllm.png)

---

### Static pattern æ–¹æ³•ç®€ä»‹

æ€»ä½“ä¸Šçœ‹ï¼Œè¿™äº›å›ºå®šçš„æ¨¡å¼å¾€å¾€ä¸èƒ½é€‚åº”æ–‡æœ¬ç”Ÿæˆä¸­å˜åŒ–çš„å…³é”® tokenï¼Œæˆ–å¤šæˆ–å°‘ä¼šæœ‰è¾ƒæ˜¾è‘—çš„ç²¾åº¦æŸå¤±ã€‚

---

### Dynamic pattern æ–¹æ³•ç®€ä»‹

1. [MInference](https://arxiv.org/abs/2407.02490) é€šè¿‡è§‚å¯Ÿæ³¨æ„åŠ›çŸ©é˜µï¼Œæ€»ç»“å‡ºä¸‰ç§å¸¸è§æ¨¡å¼ï¼Œæ ¹æ®è¾“å…¥åŠ¨æ€é€‰æ‹©æœ€åˆé€‚çš„æ¨¡å¼ï¼Œä»è€ŒåŠ é€Ÿ prefill é˜¶æ®µï¼š

<img src="../images/l9/minference.png" width="100%"/>

---

### Dynamic pattern æ–¹æ³•ç®€ä»‹

2. [Quest](https://arxiv.org/abs/2406.10774) é‡‡ç”¨åˆ†é¡µè®¾è®¡ï¼Œä¼°è®¡æ¯ä¸ª KV page ä¸å½“å‰ Q çš„ç›¸ä¼¼åº¦ï¼ŒåŠ¨æ€é€‰æ‹©æœ€ç›¸ä¼¼ï¼ˆæ¿€æ´»å€¼æœ€é«˜ï¼‰çš„ pages å‚ä¸è®¡ç®—ï¼š
![quest height:450 center](../images/l9/quest.png)

---

### Dynamic pattern æ–¹æ³•ç®€ä»‹

* ä¼˜ç‚¹ï¼šç›¸è¾ƒäº static patternï¼Œdynamic pattern ç±»çš„æ–¹æ³•ç²¾åº¦æ›´é«˜ï¼›

* ç¼ºç‚¹ï¼šç”±äºè®¡ç®—æœ€åˆé€‚çš„ tokens ä¼šå¼•å…¥ä¸€å®š overheadï¼Œç»¼åˆä¸‹æ¥ä¼šæ¯”ç®€å•çš„ static pattern æ–¹æ³•æ…¢ï¼ˆä½†æ˜¯ç›¸æ¯” dense attention è¿˜æ˜¯æœ‰åŠ é€Ÿæ•ˆæœï¼‰;åŒæ—¶ï¼Œå¦‚ä½•è®¾è®¡é€‰æ‹©ç®—æ³•ä¹Ÿä¾èµ–ç»éªŒï¼ˆå¯å‘å¼ï¼‰ã€‚

---

### Training-based æ–¹æ³•ç®€ä»‹

1. [NSA](https://arxiv.org/pdf/2502.11089) é€šè¿‡é—¨æ§æœºåˆ¶èåˆäº†ç²—ç²’åº¦ token å‹ç¼©ã€ç»†ç²’åº¦çš„ token é€‰æ‹©å’Œæ»‘åŠ¨çª—å£è¿™ä¸‰ä¸ªæ¨¡å—çš„è¾“å‡ºï¼Œä»è€Œè¾¾åˆ°ç¨€ç–æ•ˆæœã€‚

![NSA height:300 center](../images/l9/nsa.png)

---

### Training-based æ–¹æ³•ç®€ä»‹

2. [DSA](https://github.com/deepseek-ai/DeepSeek-V3.2-Exp/blob/main/DeepSeek_V3_2.pdf) ä¸»è¦åœ¨ [MLA](https://arxiv.org/abs/2412.19437) çš„åŸºç¡€ä¸ŠåŠ ä¸Šäº†ç¨€ç–æ¨¡å—ï¼ˆç»¿è‰²éƒ¨åˆ†ï¼‰ã€‚æœ¬è´¨ä¸Šï¼ŒLightning Indexer åˆ©ç”¨é‡åŒ–åï¼ˆFP8ï¼‰çš„ qk è®¡ç®— attentionï¼Œæ ¹æ®è¿™ä¸€è½»é‡è®¡ç®—é€‰æ‹©ä¸ Q æœ€ç›¸ä¼¼çš„ Kã€‚
![DSA height:400 center](../images/l9/dsa.png)

---

### Training-based æ–¹æ³•ç®€ä»‹

æ€»ä½“è€Œè¨€ï¼ŒTraining-based æ–¹æ³•ç”±äºå…¶æˆæœ¬é«˜ï¼Œå½“å‰å¤§æ¨¡å‹å‚å•†å°‘æœ‰æŠ•å…¥ã€‚ä½†ä» DeepSeek å…¬å¸ƒçš„æ•ˆæœæ¥çœ‹(NSA)ï¼Œè®­ç»ƒåçš„åŸç”Ÿ Sparse Attention ç²¾åº¦å‡ ä¹æ— æŸç”šè‡³èƒ½åè¶… Dense Attentionï¼Œæ¨ç†é€Ÿåº¦ä¹Ÿæ›´å¿«ã€‚
![nsa_performance height:350 center](../images/l9/nsa_performance.png)